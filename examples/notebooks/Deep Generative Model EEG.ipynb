{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../../semi-supervised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Generative Model\n",
    "\n",
    "In this notebook we show how you can use the deep \"generative model for semi-supervised learning\" as presented in [[Kingma 2014]](https://arxiv.org/abs/1406.5298). The paper posits three different models, though we are just interested in two of these: the M2 model and the M1+M2 model.\n",
    "\n",
    "The M1 model is just a variational autoencoder, so we refer to the previous notebook for more information on this. The M2 model however is an extension to the VAE to include label information for a semi-supervised objective. The structure is shown below (left: inference model, right: generative model).\n",
    "\n",
    "<img src=\"../images/dgm.png\" width=\"400px\"/>\n",
    "\n",
    "The point of the generative model is to seperate the partially observed label information $y$ from the latent variable $z$ in order to learn a representation that seperates these two variables. We can use this model for semi-supervised learning as the inference model must also infer the label from the data $x$ along with the latent variable $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../semi-supervised/models/vae.py:114: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(m.weight.data)\n",
      "../../semi-supervised/models/dgm.py:50: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(m.weight.data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepGenerativeModel(\n",
       "  (encoder): Encoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=794, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (log_var): Linear(in_features=128, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=42, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    )\n",
       "    (reconstruction): Linear(in_features=256, out_features=784, bias=True)\n",
       "    (output_activation): Sigmoid()\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (dense): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (logits): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import DeepGenerativeModel, StackedDeepGenerativeModel\n",
    "\n",
    "y_dim = 10\n",
    "z_dim = 32\n",
    "h_dim = [256, 128]\n",
    "\n",
    "model = DeepGenerativeModel([784, y_dim, z_dim, h_dim])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=794, out_features=256, bias=True)\n",
      "Linear(in_features=42, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.encoder.hidden[0])\n",
    "print(model.decoder.hidden[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how theres now a classifier associated with model. This classifier will just be a simple model that takes the size of the first layer encoder network. We also have a larger input space on both the encoder and decoder to make room for label information, in this case 10 labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Recall the ELBO from the VAE formulation, we want to construct a similar ELBO when we include labelled data $y$. In the case that we have labels, the ELBO has a simple formulation that is similar to the one for the VAE. The difference here is that we must also have a prior over labels $p(y)$, which we choose to be uniform over the different classes.\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(x, y) &= \\log \\int q(z|x, y) \\frac{p(x, y, z)}{q(z|xy)} \\ dz \\geq \\int q(z|x, y) \\log \\frac{p(x, y, z)}{q(z|xy)} \\ dz\\\\\n",
    "&= \\int q(z|x, y) [ \\log p(x|z,y) + \\log p(y) ] \\ dz + \\int q(z|x, y) \\log \\frac{p(z)}{q(z|xy)} \\ dz\\\\\n",
    "&= \\mathbb{E}_{q(z|x, y)} [ \\log p(x|z,y) + \\log p(y) ] - KL(p(z)||q(z|xy)) = - \\mathcal{L}(x, y)\n",
    "\\end{align}\n",
    "\n",
    "In the case when the labels are not observed, we can instead integrate over all of the labels to achieve the same effect.\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(x) &= \\log \\sum_{y} \\int q(z,y|x) \\frac{p(x, y, z)}{q(z,y|x)} \\ dz \\geq \\sum_{y} q(y|x) \\int q(z|x, y) \\log \\frac{p(x, y, z)}{q(z,y|x)} \\ dz\\\\\n",
    "&= \\sum_{y} q(y|x) \\int q(z|x, y) \\log \\frac{p(x, y, z)}{q(z,y|x)} \\ dz + \\sum_{y} q(y|x) \\log q(y|x) \\int q(z|x, y) \\ dz\\\\\n",
    "&= \\sum_{y} q(y|x) (- \\mathcal{L}(x,y)) + \\mathcal{H}(q(y|x)) = - \\mathcal{U}(x)\n",
    "\\end{align}\n",
    "\n",
    "Notice how in both cases we need to compute the labelled bound, but in the unlabelled case we need to do it $n$ times where $n$ is the number of classes. In this model, we do not learn directly from the labelled class, as there is no cross entropy term between $y$ and our model output $q(y|x)$. We therefore add an auxiliary loss to arrive at the final loss objective.\n",
    "\n",
    "$$\\mathcal{J}^{\\alpha} = \\sum_{(x_l, y_l)}\\mathcal{L}(x_l, y_l) + \\alpha \\cdot \\mathbb{E}_{x_l, y_l}[- \\log q(y_l|x_l)] + \\sum_{(x_u)}\\mathcal{U}(x_u)$$\n",
    "\n",
    "Where $l, u$ denotes labelled and unlabelled data respectively and $\\alpha$ is a hyperparameter that denotes the reliance of labelled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import get_mnist\n",
    "\n",
    "# Only use 10 labelled examples per class\n",
    "# The rest of the data is unlabelled.\n",
    "labelled, unlabelled, validation = get_mnist(location=\"./\", batch_size=64, labels_per_class=10)\n",
    "alpha = 0.1 * len(unlabelled) / len(labelled)\n",
    "\n",
    "def binary_cross_entropy(r, x):\n",
    "    return -torch.sum(x * torch.log(r + 1e-8) + (1 - x) * torch.log(1 - r + 1e-8), dim=-1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Labelled batches 2\n",
      "# Unlabelled batches 938\n"
     ]
    }
   ],
   "source": [
    "print(\"# Labelled batches\", len(labelled))\n",
    "print(\"# Unlabelled batches\", len(unlabelled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from inference import SVI, ImportanceWeightedSampler\n",
    "\n",
    "# You can use importance weighted samples [Burda, 2015] to get a better estimate\n",
    "# on the log-likelihood.\n",
    "sampler = ImportanceWeightedSampler(mc=1, iw=1)\n",
    "\n",
    "if cuda: model = model.cuda()\n",
    "elbo = SVI(model, likelihood=binary_cross_entropy, sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library is conventially packed with the `SVI` method that does all of the work of calculating the lower bound for both labelled and unlabelled data depending on whether the label is given. It also manages to perform the enumeration of all the labels.\n",
    "\n",
    "Remember that the labels have to be in a *one-hot encoded* format in order to work with SVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "[Train]\t\t J_a: 266.51, accuracy: 1.00\n",
      "[Validation]\t J_a: 340.99, accuracy: 0.77\n",
      "Epoch: 1\n",
      "[Train]\t\t J_a: 244.08, accuracy: 1.00\n",
      "[Validation]\t J_a: 338.01, accuracy: 0.79\n",
      "Epoch: 2\n",
      "[Train]\t\t J_a: 232.03, accuracy: 1.00\n",
      "[Validation]\t J_a: 341.90, accuracy: 0.78\n",
      "Epoch: 3\n",
      "[Train]\t\t J_a: 224.42, accuracy: 1.00\n",
      "[Validation]\t J_a: 340.06, accuracy: 0.81\n",
      "Epoch: 4\n",
      "[Train]\t\t J_a: 217.60, accuracy: 1.00\n",
      "[Validation]\t J_a: 347.90, accuracy: 0.80\n",
      "Epoch: 5\n",
      "[Train]\t\t J_a: 212.31, accuracy: 1.00\n",
      "[Validation]\t J_a: 345.73, accuracy: 0.81\n",
      "Epoch: 6\n",
      "[Train]\t\t J_a: 208.18, accuracy: 1.00\n",
      "[Validation]\t J_a: 352.34, accuracy: 0.80\n",
      "Epoch: 7\n",
      "[Train]\t\t J_a: 205.82, accuracy: 1.00\n",
      "[Validation]\t J_a: 351.76, accuracy: 0.80\n",
      "Epoch: 8\n",
      "[Train]\t\t J_a: 203.05, accuracy: 1.00\n",
      "[Validation]\t J_a: 351.36, accuracy: 0.81\n",
      "Epoch: 9\n",
      "[Train]\t\t J_a: 201.03, accuracy: 1.00\n",
      "[Validation]\t J_a: 356.40, accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss, accuracy = (0, 0)\n",
    "    for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "        # Wrap in variables\n",
    "        x, y, u = Variable(x), Variable(y), Variable(u)\n",
    "\n",
    "        if cuda:\n",
    "            # They need to be on the same device and be synchronized.\n",
    "            x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "            u = u.cuda(device=0)\n",
    "\n",
    "        L = -elbo(x, y)\n",
    "        U = -elbo(u)\n",
    "\n",
    "        # Add auxiliary classification loss q(y|x)\n",
    "        logits = model.classify(x)\n",
    "        \n",
    "        # Regular cross entropy\n",
    "        classication_loss = torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "        J_alpha = L - alpha * classication_loss + U\n",
    "\n",
    "        J_alpha.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        total_loss += J_alpha.item()\n",
    "#         total_loss += J_alpha.data[0]\n",
    "        accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        m = len(unlabelled)\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        print(\"[Train]\\t\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for x, y in validation:\n",
    "            x, y = Variable(x), Variable(y)\n",
    "\n",
    "            if cuda:\n",
    "                x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "\n",
    "            L = -elbo(x, y)\n",
    "            U = -elbo(x)\n",
    "\n",
    "            logits = model.classify(x)\n",
    "            classication_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "            J_alpha = L + alpha * classication_loss + U\n",
    "\n",
    "#             total_loss += J_alpha.data[0]\n",
    "            total_loss += J_alpha.item()\n",
    "\n",
    "            _, pred_idx = torch.max(logits, 1)\n",
    "            _, lab_idx = torch.max(y, 1)\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "        m = len(validation)\n",
    "        print(\"[Validation]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional generation\n",
    "\n",
    "When the model is done training you can generate samples conditionally given some normal distributed noise $z$ and a label $y$.\n",
    "\n",
    "*The model below has only trained for 10 iterations, so the perfomance is not representative*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import onehot\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# z = Variable(torch.randn(16, 32))\n",
    "z = Variable(torch.arange(0, 512).view(16, 32).type(torch.FloatTensor)) / (32* 6) -1\n",
    "\n",
    "# Generate a batch of 8s\n",
    "y = Variable(onehot(10)(8).repeat(16, 1))\n",
    "\n",
    "x_mu = model.sample(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBEAAABXCAYAAABStd0JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1329cf668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1, 16, figsize=(18, 12))\n",
    "\n",
    "samples = x_mu.data.view(-1, 28, 28).numpy()\n",
    "\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.imshow(samples[i])\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Deep Generative Model\n",
    "\n",
    "The M1+M2 model also described in the same paper is an M1 model (VAE) with an M2 model stacked on top of it. That means that we train the a VAE end-to-end on the data given dataset, then we use the learned encoder as a feature extractor and feed the data transformed by the M1 encoder into the M2 model.\n",
    "\n",
    "We approach is somewhat similar to restricted boltzmann machines (RBMs) in the sense that we perform a layerwise training of the whole model by first training a level-1 feature extractor and stacking another model on top of this. The stacked model is therefore also more modular, but cannot be trained end-to-end, which is a downside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import VariationalAutoencoder, StackedDeepGenerativeModel\n",
    "\n",
    "features = VariationalAutoencoder([784, z_dim, h_dim])\n",
    "model = StackedDeepGenerativeModel([784, y_dim, z_dim, h_dim], features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, you would want to load a pretrained feature extractor VAE instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = torch.load(\"./your-pretrained-vae.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss, accuracy = (0, 0)\n",
    "    for (x, y), (u, _) in zip(cycle(labelled), unlabelled):\n",
    "        # Wrap in variables\n",
    "        x, y, u = Variable(x), Variable(y), Variable(u)\n",
    "\n",
    "        if cuda:\n",
    "            # They need to be on the same device and be synchronized.\n",
    "            x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "            u = u.cuda(device=0)\n",
    "\n",
    "        L = -elbo(x, y)\n",
    "        U = -elbo(u)\n",
    "\n",
    "        # Add auxiliary classification loss q(y|x)\n",
    "        logits = model.classify(x)\n",
    "        \n",
    "        # Regular cross entropy\n",
    "        classication_loss = torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "        J_alpha = L - alpha * classication_loss + U\n",
    "\n",
    "        J_alpha.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += J_alpha.data[0]\n",
    "        accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        m = len(unlabelled)\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        print(\"[Train]\\t\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))\n",
    "\n",
    "        total_loss, accuracy = (0, 0)\n",
    "        for x, y in validation:\n",
    "            x, y = Variable(x), Variable(y)\n",
    "\n",
    "            if cuda:\n",
    "                x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "\n",
    "            L = -elbo(x, y)\n",
    "            U = -elbo(x)\n",
    "\n",
    "            logits = model.classify(x)\n",
    "            classication_loss = -torch.sum(y * torch.log(logits + 1e-8), dim=1).mean()\n",
    "\n",
    "            J_alpha = L + alpha * classication_loss + U\n",
    "\n",
    "            total_loss += J_alpha.data[0]\n",
    "\n",
    "            _, pred_idx = torch.max(logits, 1)\n",
    "            _, lab_idx = torch.max(y, 1)\n",
    "            accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "        m = len(validation)\n",
    "        print(\"[Validation]\\t J_a: {:.2f}, accuracy: {:.2f}\".format(total_loss / m, accuracy / m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tips\n",
    "\n",
    "You can change the built-in classifier with your own, for example if you want a CNN as a classifier you can do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvolutionalClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalClassifier, self).__init__()        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=4)\n",
    "\n",
    "        size = int((28 - 3) + 1)//4\n",
    "        size = int((size - 3) + 1)//4\n",
    "                \n",
    "        self.fc1 = nn.Linear(32*size**2, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, *_ = x.size()\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(x.view(batch, -1))\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=-1)\n",
    "\n",
    "classifier = ConvolutionalClassifier()\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepGenerativeModel(\n",
       "  (encoder): Encoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=794, out_features=256)\n",
       "      (1): Linear(in_features=256, out_features=128)\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=128, out_features=32)\n",
       "      (log_var): Linear(in_features=128, out_features=32)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (hidden): ModuleList(\n",
       "      (0): Linear(in_features=42, out_features=128)\n",
       "      (1): Linear(in_features=128, out_features=256)\n",
       "    )\n",
       "    (reconstruction): Linear(in_features=256, out_features=784)\n",
       "    (output_activation): Sigmoid()\n",
       "  )\n",
       "  (classifier): ConvolutionalClassifier(\n",
       "    (conv1): Conv2d (1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv2): Conv2d (64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=(4, 4), stride=(4, 4), dilation=(1, 1))\n",
       "    (fc1): Linear(in_features=32, out_features=50)\n",
       "    (fc2): Linear(in_features=50, out_features=10)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
